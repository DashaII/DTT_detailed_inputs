/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[I 240428 02:39:09 trainer:10] Start training...
[I 240428 02:39:09 trainer:13] 
    ====== Epoch 1/12 Training ======
[I 240428 02:39:51 trainer:32] loss: 7.34796142578125
[I 240428 02:40:23 trainer:32] loss: 7.831532955169678
[I 240428 02:40:57 trainer:32] loss: 6.251482963562012
[I 240428 02:41:32 trainer:32] loss: 5.557788372039795
[I 240428 02:42:08 trainer:32] loss: 4.93665885925293
[I 240428 02:42:45 trainer:32] loss: 3.9662797451019287
[I 240428 02:43:24 trainer:32] loss: 3.8130152225494385
[I 240428 02:44:02 trainer:32] loss: 3.245744466781616
[I 240428 02:44:40 trainer:32] loss: 3.7640504837036133
[I 240428 02:45:19 trainer:32] loss: 2.7586007118225098
[I 240428 02:45:58 trainer:32] loss: 2.638249158859253
[I 240428 02:46:36 trainer:32] loss: 2.850942850112915
[I 240428 02:47:14 trainer:32] loss: 2.3426694869995117
[I 240428 02:47:52 trainer:32] loss: 1.9298813343048096
[I 240428 02:48:30 trainer:32] loss: 1.9628944396972656
[I 240428 02:49:08 trainer:32] loss: 2.085587501525879
[I 240428 02:49:45 trainer:32] loss: 2.1066627502441406
[I 240428 02:50:22 trainer:32] loss: 1.8859463930130005
[I 240428 02:50:59 trainer:32] loss: 1.8800179958343506
[I 240428 02:51:36 trainer:32] loss: 2.191263437271118
[I 240428 02:52:05 trainer:35] 
    Accuracy: 0.6107278165503489
[I 240428 02:52:42 trainer:32] loss: 1.7267494201660156
[I 240428 02:53:19 trainer:32] loss: 1.72524094581604
[I 240428 02:53:56 trainer:32] loss: 1.5663286447525024
[I 240428 02:54:33 trainer:32] loss: 1.6717579364776611
[I 240428 02:55:12 trainer:32] loss: 1.4622772932052612
[I 240428 02:55:49 trainer:32] loss: 1.0802092552185059
[I 240428 02:56:28 trainer:32] loss: 1.8089981079101562
[I 240428 02:57:06 trainer:32] loss: 1.3945294618606567
[I 240428 02:57:45 trainer:32] loss: 1.040051817893982
[I 240428 02:58:22 trainer:32] loss: 1.2574959993362427
[I 240428 02:59:01 trainer:32] loss: 1.4547141790390015
[I 240428 02:59:39 trainer:32] loss: 1.002335786819458
[I 240428 03:00:17 trainer:32] loss: 1.5505421161651611
[I 240428 03:00:55 trainer:32] loss: 1.810199499130249
[I 240428 03:01:34 trainer:32] loss: 1.468679666519165
[I 240428 03:02:12 trainer:32] loss: 1.3916584253311157
[I 240428 03:02:51 trainer:32] loss: 1.3941699266433716
[I 240428 03:03:29 trainer:32] loss: 1.2186359167099
[I 240428 03:04:07 trainer:32] loss: 1.1989511251449585
[I 240428 03:04:45 trainer:32] loss: 1.4428476095199585
[I 240428 03:05:16 trainer:35] 
    Accuracy: 0.7002991026919242
[I 240428 03:05:54 trainer:32] loss: 1.279332160949707
[I 240428 03:06:32 trainer:32] loss: 1.582923412322998
[I 240428 03:07:09 trainer:32] loss: 1.3130457401275635
[I 240428 03:07:47 trainer:32] loss: 1.4423210620880127
[I 240428 03:08:28 trainer:38] 
    VALID Accuracy after epoch 1: 0.7081555333998006
[I 240428 03:19:53 trainer:40] 
    TRAIN Accuracy after epoch 1: 0.7123123848696071
[I 240428 03:19:53 trainer:13] 
    ====== Epoch 2/12 Training ======
[I 240428 03:20:32 trainer:32] loss: 1.5354875326156616
[I 240428 03:21:11 trainer:32] loss: 1.4532824754714966
[I 240428 03:21:49 trainer:32] loss: 1.4364956617355347
[I 240428 03:22:27 trainer:32] loss: 2.1653378009796143
[I 240428 03:23:06 trainer:32] loss: 1.922316074371338
[I 240428 03:23:45 trainer:32] loss: 1.5678280591964722
[I 240428 03:24:24 trainer:32] loss: 2.1052558422088623
[I 240428 03:25:02 trainer:32] loss: 1.563470482826233
[I 240428 03:25:40 trainer:32] loss: 1.680023193359375
[I 240428 03:26:19 trainer:32] loss: 1.6316111087799072
[I 240428 03:26:57 trainer:32] loss: 1.86199951171875
[I 240428 03:27:36 trainer:32] loss: 1.7127025127410889
[I 240428 03:28:15 trainer:32] loss: 1.2149090766906738
[I 240428 03:28:54 trainer:32] loss: 1.7265173196792603
[I 240428 03:29:33 trainer:32] loss: 1.3737494945526123
[I 240428 03:30:11 trainer:32] loss: 1.6364073753356934
[I 240428 03:30:50 trainer:32] loss: 1.5815374851226807
[I 240428 03:31:29 trainer:32] loss: 1.1916816234588623
[I 240428 03:32:08 trainer:32] loss: 1.1475496292114258
[I 240428 03:32:48 trainer:32] loss: 1.397953748703003
[I 240428 03:33:18 trainer:35] 
    Accuracy: 0.6991026919242274
[I 240428 03:33:56 trainer:32] loss: 1.3555275201797485
[I 240428 03:34:34 trainer:32] loss: 1.4044780731201172
[I 240428 03:35:13 trainer:32] loss: 1.330992579460144
[I 240428 03:35:51 trainer:32] loss: 1.1917468309402466
[I 240428 03:36:29 trainer:32] loss: 1.04433012008667
[I 240428 03:37:07 trainer:32] loss: 1.229057788848877
[I 240428 03:37:45 trainer:32] loss: 0.9175978302955627
[I 240428 03:38:23 trainer:32] loss: 0.9465163946151733
[I 240428 03:39:01 trainer:32] loss: 1.3433094024658203
[I 240428 03:39:39 trainer:32] loss: 1.1246098279953003
[I 240428 03:40:17 trainer:32] loss: 0.9041051268577576
[I 240428 03:40:55 trainer:32] loss: 1.2111459970474243
[I 240428 03:41:33 trainer:32] loss: 0.8746451735496521
[I 240428 03:42:10 trainer:32] loss: 1.2005386352539062
[I 240428 03:42:48 trainer:32] loss: 0.8288172483444214
[I 240428 03:43:26 trainer:32] loss: 1.4666192531585693
[I 240428 03:44:04 trainer:32] loss: 0.8967314958572388
[I 240428 03:44:43 trainer:32] loss: 1.1913901567459106
[I 240428 03:45:20 trainer:32] loss: 0.8485298156738281
[I 240428 03:45:58 trainer:32] loss: 1.0943917036056519
[I 240428 03:46:28 trainer:35] 
    Accuracy: 0.7239481555333998
[I 240428 03:47:06 trainer:32] loss: 1.106701374053955
[I 240428 03:47:44 trainer:32] loss: 1.0049458742141724
[I 240428 03:48:21 trainer:32] loss: 1.0823489427566528
[I 240428 03:48:59 trainer:32] loss: 0.9373018741607666
[I 240428 03:49:40 trainer:38] 
    VALID Accuracy after epoch 2: 0.7239082751744765
[I 240428 04:01:13 trainer:40] 
    TRAIN Accuracy after epoch 2: 0.7333479426602648
[I 240428 04:01:13 trainer:13] 
    ====== Epoch 3/12 Training ======
[I 240428 04:01:52 trainer:32] loss: 1.5818384885787964
[I 240428 04:02:30 trainer:32] loss: 1.5635896921157837
[I 240428 04:03:07 trainer:32] loss: 1.4466235637664795
[I 240428 04:03:45 trainer:32] loss: 1.61932373046875
[I 240428 04:04:22 trainer:32] loss: 1.790639042854309
[I 240428 04:04:59 trainer:32] loss: 1.1663826704025269
[I 240428 04:05:36 trainer:32] loss: 1.584586501121521
[I 240428 04:06:12 trainer:32] loss: 1.3349125385284424
[I 240428 04:06:49 trainer:32] loss: 1.8822805881500244
[I 240428 04:07:25 trainer:32] loss: 1.2538573741912842
[I 240428 04:08:01 trainer:32] loss: 1.4455615282058716
[I 240428 04:08:38 trainer:32] loss: 1.1720296144485474
[I 240428 04:09:14 trainer:32] loss: 1.1005939245224
[I 240428 04:09:51 trainer:32] loss: 1.623617172241211
[I 240428 04:10:28 trainer:32] loss: 1.3354315757751465
[I 240428 04:11:05 trainer:32] loss: 1.3986010551452637
[I 240428 04:11:42 trainer:32] loss: 1.2756143808364868
[I 240428 04:12:19 trainer:32] loss: 1.147648572921753
[I 240428 04:12:57 trainer:32] loss: 1.238550066947937
[I 240428 04:13:34 trainer:32] loss: 1.3803178071975708
[I 240428 04:14:03 trainer:35] 
    Accuracy: 0.7288733798604188
[I 240428 04:14:40 trainer:32] loss: 1.3894857168197632
[I 240428 04:15:16 trainer:32] loss: 1.1685341596603394
[I 240428 04:15:53 trainer:32] loss: 0.7932571172714233
[I 240428 04:16:30 trainer:32] loss: 1.0459437370300293
[I 240428 04:17:07 trainer:32] loss: 1.2280232906341553
[I 240428 04:17:43 trainer:32] loss: 1.040182113647461
[I 240428 04:18:20 trainer:32] loss: 0.7348605394363403
[I 240428 04:18:58 trainer:32] loss: 0.9746866822242737
[I 240428 04:19:34 trainer:32] loss: 0.9660910367965698
[I 240428 04:20:11 trainer:32] loss: 0.9536606669425964
[I 240428 04:20:48 trainer:32] loss: 1.0097111463546753
[I 240428 04:21:25 trainer:32] loss: 0.9721576571464539
[I 240428 04:22:02 trainer:32] loss: 0.9673380255699158
[I 240428 04:22:39 trainer:32] loss: 0.9014738202095032
[I 240428 04:23:15 trainer:32] loss: 0.8850583434104919
[I 240428 04:23:52 trainer:32] loss: 1.1271381378173828
[I 240428 04:24:29 trainer:32] loss: 0.9563263654708862
[I 240428 04:25:06 trainer:32] loss: 1.0755199193954468
[I 240428 04:25:43 trainer:32] loss: 1.1105175018310547
[I 240428 04:26:20 trainer:32] loss: 0.8894267678260803
[I 240428 04:26:50 trainer:35] 
    Accuracy: 0.7431306081754736
[I 240428 04:27:27 trainer:32] loss: 1.097293734550476
[I 240428 04:28:04 trainer:32] loss: 0.9148379564285278
[I 240428 04:28:41 trainer:32] loss: 1.058021068572998
[I 240428 04:29:18 trainer:32] loss: 0.8437447547912598
[I 240428 04:29:58 trainer:38] 
    VALID Accuracy after epoch 3: 0.7462811565304088
[I 240428 04:41:16 trainer:40] 
    TRAIN Accuracy after epoch 3: 0.7580114833055662
[I 240428 04:41:16 trainer:13] 
    ====== Epoch 4/12 Training ======
[I 240428 04:41:54 trainer:32] loss: 1.3570075035095215
[I 240428 04:42:32 trainer:32] loss: 3.1116466522216797
[I 240428 04:43:11 trainer:32] loss: 2.7158203125
[I 240428 04:43:48 trainer:32] loss: 2.3863813877105713
[I 240428 04:44:26 trainer:32] loss: 2.4476821422576904
[I 240428 04:45:04 trainer:32] loss: 2.1446197032928467
[I 240428 04:45:43 trainer:32] loss: 1.7082849740982056
[I 240428 04:46:21 trainer:32] loss: 2.463130474090576
[I 240428 04:46:59 trainer:32] loss: 2.0081212520599365
[I 240428 04:47:37 trainer:32] loss: 1.725724458694458
[I 240428 04:48:15 trainer:32] loss: 2.2543654441833496
[I 240428 04:48:53 trainer:32] loss: 2.1624791622161865
[I 240428 04:49:33 trainer:32] loss: 1.7789465188980103
[I 240428 04:50:10 trainer:32] loss: 1.834655523300171
[I 240428 04:50:48 trainer:32] loss: 2.263590097427368
[I 240428 04:51:25 trainer:32] loss: 1.9906610250473022
[I 240428 04:52:03 trainer:32] loss: 1.449791669845581
[I 240428 04:52:40 trainer:32] loss: 1.3730472326278687
[I 240428 04:53:17 trainer:32] loss: 1.8507015705108643
[I 240428 04:53:54 trainer:32] loss: 1.5899170637130737
[I 240428 04:54:23 trainer:35] 
    Accuracy: 0.6707676969092722
[I 240428 04:55:00 trainer:32] loss: 1.6432678699493408
[I 240428 04:55:36 trainer:32] loss: 1.361501693725586
[I 240428 04:56:13 trainer:32] loss: 1.1135623455047607
[I 240428 04:56:50 trainer:32] loss: 1.362239956855774
[I 240428 04:57:26 trainer:32] loss: 1.564197063446045
[I 240428 04:58:02 trainer:32] loss: 1.235182523727417
[I 240428 04:58:39 trainer:32] loss: 1.5766626596450806
[I 240428 04:59:15 trainer:32] loss: 1.2064920663833618
[I 240428 04:59:52 trainer:32] loss: 0.8379015922546387
[I 240428 05:00:28 trainer:32] loss: 1.263144850730896
[I 240428 05:01:05 trainer:32] loss: 1.1841959953308105
[I 240428 05:01:41 trainer:32] loss: 1.2404224872589111
[I 240428 05:02:18 trainer:32] loss: 1.2428863048553467
[I 240428 05:02:55 trainer:32] loss: 1.081902265548706
[I 240428 05:03:31 trainer:32] loss: 1.074937343597412
[I 240428 05:04:08 trainer:32] loss: 1.5544356107711792
[I 240428 05:04:45 trainer:32] loss: 1.1378315687179565
[I 240428 05:05:21 trainer:32] loss: 1.2451472282409668
[I 240428 05:05:58 trainer:32] loss: 1.0930531024932861
[I 240428 05:06:35 trainer:32] loss: 0.9006808400154114
[I 240428 05:07:04 trainer:35] 
    Accuracy: 0.6975074775672981
[I 240428 05:07:41 trainer:32] loss: 1.4313980340957642
[I 240428 05:08:18 trainer:32] loss: 1.3966004848480225
[I 240428 05:08:54 trainer:32] loss: 1.1536526679992676
[I 240428 05:09:31 trainer:32] loss: 0.7729849219322205
[I 240428 05:10:10 trainer:38] 
    VALID Accuracy after epoch 4: 0.6984047856430707
[I 240428 05:21:19 trainer:40] 
    TRAIN Accuracy after epoch 4: 0.7101603186331663
[I 240428 05:21:19 trainer:13] 
    ====== Epoch 5/12 Training ======
[I 240428 05:21:57 trainer:32] loss: 1.6687368154525757
[I 240428 05:22:33 trainer:32] loss: 1.7320976257324219
[I 240428 05:23:10 trainer:32] loss: 1.686438798904419
[I 240428 05:23:47 trainer:32] loss: 1.518504023551941
[I 240428 05:24:23 trainer:32] loss: 1.4652518033981323
[I 240428 05:25:00 trainer:32] loss: 1.298253059387207
[I 240428 05:25:37 trainer:32] loss: 1.7616714239120483
[I 240428 05:26:14 trainer:32] loss: 1.505456566810608
[I 240428 05:26:51 trainer:32] loss: 1.398156762123108
[I 240428 05:27:30 trainer:32] loss: 1.4233100414276123
[I 240428 05:28:08 trainer:32] loss: 1.5467004776000977
[I 240428 05:28:46 trainer:32] loss: 1.285275936126709
[I 240428 05:29:24 trainer:32] loss: 1.823405385017395
[I 240428 05:30:02 trainer:32] loss: 1.635092854499817
[I 240428 05:30:40 trainer:32] loss: 1.5048949718475342
[I 240428 05:31:18 trainer:32] loss: 1.7886296510696411
[I 240428 05:31:56 trainer:32] loss: 1.4521629810333252
[I 240428 05:32:34 trainer:32] loss: 1.5774083137512207
[I 240428 05:33:13 trainer:32] loss: 1.7557992935180664
[I 240428 05:33:52 trainer:32] loss: 1.3257278203964233
[I 240428 05:34:22 trainer:35] 
    Accuracy: 0.6969890329012961
[I 240428 05:35:00 trainer:32] loss: 1.2758476734161377
[I 240428 05:35:38 trainer:32] loss: 1.025447130203247
[I 240428 05:36:16 trainer:32] loss: 1.2523540258407593
[I 240428 05:36:53 trainer:32] loss: 1.3222296237945557
[I 240428 05:37:31 trainer:32] loss: 1.009929895401001
[I 240428 05:38:09 trainer:32] loss: 1.2216193675994873
[I 240428 05:38:48 trainer:32] loss: 1.0182386636734009
[I 240428 05:39:25 trainer:32] loss: 1.040460467338562
[I 240428 05:40:04 trainer:32] loss: 1.1178475618362427
[I 240428 05:40:42 trainer:32] loss: 1.1825814247131348
[I 240428 05:41:19 trainer:32] loss: 1.0300934314727783
[I 240428 05:41:58 trainer:32] loss: 1.495412826538086
[I 240428 05:42:36 trainer:32] loss: 0.9749664664268494
[I 240428 05:43:13 trainer:32] loss: 1.4777092933654785
[I 240428 05:43:51 trainer:32] loss: 1.1951690912246704
[I 240428 05:44:29 trainer:32] loss: 0.9019163846969604
[I 240428 05:45:07 trainer:32] loss: 1.2007663249969482
[I 240428 05:45:45 trainer:32] loss: 1.2254053354263306
[I 240428 05:46:22 trainer:32] loss: 1.2085931301116943
[I 240428 05:47:00 trainer:32] loss: 1.0590215921401978
[I 240428 05:47:30 trainer:35] 
    Accuracy: 0.7040877367896311
[I 240428 05:48:07 trainer:32] loss: 1.464185118675232
[I 240428 05:48:45 trainer:32] loss: 1.2033072710037231
[I 240428 05:49:22 trainer:32] loss: 0.8260141015052795
[I 240428 05:49:59 trainer:32] loss: 1.068202257156372
[I 240428 05:50:38 trainer:38] 
    VALID Accuracy after epoch 5: 0.7086340977068794
[I 240428 06:01:44 trainer:40] 
    TRAIN Accuracy after epoch 5: 0.7229425432028702
[I 240428 06:01:44 trainer:13] 
    ====== Epoch 6/12 Training ======
[I 240428 06:02:22 trainer:32] loss: 1.5622655153274536
[I 240428 06:02:59 trainer:32] loss: 1.434433937072754
[I 240428 06:03:36 trainer:32] loss: 1.2993993759155273
[I 240428 06:04:14 trainer:32] loss: 1.4398711919784546
[I 240428 06:04:51 trainer:32] loss: 1.8716518878936768
[I 240428 06:05:29 trainer:32] loss: 1.5121667385101318
[I 240428 06:06:06 trainer:32] loss: 1.8256752490997314
[I 240428 06:06:43 trainer:32] loss: 1.5128198862075806
[I 240428 06:07:21 trainer:32] loss: 1.6964294910430908
[I 240428 06:07:58 trainer:32] loss: 1.8745542764663696
[I 240428 06:08:36 trainer:32] loss: 1.2622426748275757
[I 240428 06:09:13 trainer:32] loss: 1.8844188451766968
[I 240428 06:09:51 trainer:32] loss: 1.4594484567642212
[I 240428 06:10:28 trainer:32] loss: 1.3393683433532715
[I 240428 06:11:06 trainer:32] loss: 1.0027797222137451
[I 240428 06:11:43 trainer:32] loss: 1.5771960020065308
[I 240428 06:12:21 trainer:32] loss: 1.3923455476760864
[I 240428 06:12:58 trainer:32] loss: 1.1514230966567993
[I 240428 06:13:36 trainer:32] loss: 1.6269919872283936
[I 240428 06:14:15 trainer:32] loss: 1.7997708320617676
[I 240428 06:14:44 trainer:35] 
    Accuracy: 0.704925224327019
[I 240428 06:15:22 trainer:32] loss: 1.092543363571167
[I 240428 06:15:59 trainer:32] loss: 1.110023021697998
[I 240428 06:16:36 trainer:32] loss: 1.1339837312698364
[I 240428 06:17:14 trainer:32] loss: 0.9409884214401245
[I 240428 06:17:51 trainer:32] loss: 1.1438335180282593
[I 240428 06:18:29 trainer:32] loss: 0.9644930958747864
[I 240428 06:19:06 trainer:32] loss: 1.1044374704360962
[I 240428 06:19:44 trainer:32] loss: 0.7973037958145142
[I 240428 06:20:21 trainer:32] loss: 1.2035566568374634
[I 240428 06:20:58 trainer:32] loss: 0.9592119455337524
[I 240428 06:21:36 trainer:32] loss: 0.8352389931678772
[I 240428 06:22:13 trainer:32] loss: 1.2031766176223755
[I 240428 06:22:51 trainer:32] loss: 1.008347988128662
[I 240428 06:23:28 trainer:32] loss: 1.5164846181869507
[I 240428 06:24:05 trainer:32] loss: 0.6751856207847595
[I 240428 06:24:44 trainer:32] loss: 1.1112818717956543
[I 240428 06:25:21 trainer:32] loss: 1.3211798667907715
[I 240428 06:25:59 trainer:32] loss: 0.8710154891014099
[I 240428 06:26:37 trainer:32] loss: 0.9611377716064453
[I 240428 06:27:14 trainer:32] loss: 1.230973243713379
[I 240428 06:27:44 trainer:35] 
    Accuracy: 0.7011764705882353
[I 240428 06:28:22 trainer:32] loss: 1.0720070600509644
[I 240428 06:28:59 trainer:32] loss: 1.1938186883926392
[I 240428 06:29:37 trainer:32] loss: 0.916573703289032
[I 240428 06:30:14 trainer:32] loss: 1.1773744821548462
[I 240428 06:30:54 trainer:38] 
    VALID Accuracy after epoch 6: 0.7098504486540379
[I 240428 06:41:50 trainer:40] 
    TRAIN Accuracy after epoch 6: 0.7241918279545725
[I 240428 06:41:50 trainer:13] 
    ====== Epoch 7/12 Training ======
[I 240428 06:42:27 trainer:32] loss: 1.5150171518325806
[I 240428 06:43:04 trainer:32] loss: 1.2864041328430176
[I 240428 06:43:41 trainer:32] loss: 1.8111673593521118
[I 240428 06:44:19 trainer:32] loss: 1.6140881776809692
[I 240428 06:44:56 trainer:32] loss: 1.3804978132247925
[I 240428 06:45:33 trainer:32] loss: 1.6222814321517944
[I 240428 06:46:10 trainer:32] loss: 1.545179009437561
[I 240428 06:46:47 trainer:32] loss: 1.5686852931976318
[I 240428 06:47:24 trainer:32] loss: 1.5262644290924072
[I 240428 06:48:02 trainer:32] loss: 1.363316535949707
[I 240428 06:48:39 trainer:32] loss: 1.5642961263656616
[I 240428 06:49:16 trainer:32] loss: 1.5991092920303345
[I 240428 06:49:53 trainer:32] loss: 1.6642656326293945
[I 240428 06:50:30 trainer:32] loss: 1.8039393424987793
[I 240428 06:51:07 trainer:32] loss: 1.7889313697814941
[I 240428 06:51:44 trainer:32] loss: 1.3689205646514893
[I 240428 06:52:21 trainer:32] loss: 1.6566060781478882
[I 240428 06:52:59 trainer:32] loss: 1.6266690492630005
[I 240428 06:53:36 trainer:32] loss: 1.2108235359191895
[I 240428 06:54:14 trainer:32] loss: 1.5877387523651123
[I 240428 06:54:43 trainer:35] 
    Accuracy: 0.6983449651046859
[I 240428 06:55:20 trainer:32] loss: 1.1208951473236084
[I 240428 06:55:57 trainer:32] loss: 0.8913023471832275
[I 240428 06:56:34 trainer:32] loss: 1.2119232416152954
[I 240428 06:57:11 trainer:32] loss: 1.5414173603057861
[I 240428 06:57:47 trainer:32] loss: 1.0795707702636719
[I 240428 06:58:24 trainer:32] loss: 1.3115257024765015
[I 240428 06:59:03 trainer:32] loss: 1.0833368301391602
[I 240428 06:59:40 trainer:32] loss: 1.1762248277664185
[I 240428 07:00:16 trainer:32] loss: 1.195380687713623
[I 240428 07:00:54 trainer:32] loss: 1.1869463920593262
[I 240428 07:01:30 trainer:32] loss: 1.2093958854675293
[I 240428 07:02:08 trainer:32] loss: 0.9419013857841492
[I 240428 07:02:45 trainer:32] loss: 0.8892471194267273
[I 240428 07:03:22 trainer:32] loss: 0.8843126893043518
[I 240428 07:03:59 trainer:32] loss: 1.060468077659607
[I 240428 07:04:36 trainer:32] loss: 1.2809244394302368
[I 240428 07:05:13 trainer:32] loss: 0.9845883250236511
[I 240428 07:05:50 trainer:32] loss: 0.942401111125946
[I 240428 07:06:27 trainer:32] loss: 0.9705806374549866
[I 240428 07:07:04 trainer:32] loss: 1.137717604637146
[I 240428 07:07:34 trainer:35] 
    Accuracy: 0.6861814556331007
[I 240428 07:08:12 trainer:32] loss: 1.2798491716384888
[I 240428 07:08:49 trainer:32] loss: 1.0777958631515503
[I 240428 07:09:25 trainer:32] loss: 1.2007111310958862
[I 240428 07:10:03 trainer:32] loss: 1.249057650566101
[I 240428 07:10:42 trainer:38] 
    VALID Accuracy after epoch 7: 0.6892323030907278
[I 240428 07:21:43 trainer:40] 
    TRAIN Accuracy after epoch 7: 0.7061558646614429
[I 240428 07:21:43 trainer:13] 
    ====== Epoch 8/12 Training ======
[I 240428 07:22:20 trainer:32] loss: 1.5826189517974854
[I 240428 07:22:57 trainer:32] loss: 1.6083062887191772
[I 240428 07:23:34 trainer:32] loss: 1.597277045249939
[I 240428 07:24:12 trainer:32] loss: 1.8109015226364136
[I 240428 07:24:49 trainer:32] loss: 1.5865809917449951
[I 240428 07:25:26 trainer:32] loss: 1.8921610116958618
[I 240428 07:26:03 trainer:32] loss: 1.7934527397155762
[I 240428 07:26:40 trainer:32] loss: 1.6147730350494385
[I 240428 07:27:17 trainer:32] loss: 1.7209298610687256
[I 240428 07:27:54 trainer:32] loss: 1.5551502704620361
[I 240428 07:28:31 trainer:32] loss: 1.468074083328247
[I 240428 07:29:09 trainer:32] loss: 1.6274304389953613
[I 240428 07:29:46 trainer:32] loss: 1.7389874458312988
[I 240428 07:30:23 trainer:32] loss: 2.009871482849121
[I 240428 07:31:00 trainer:32] loss: 1.7042572498321533
[I 240428 07:31:37 trainer:32] loss: 2.167171001434326
[I 240428 07:32:14 trainer:32] loss: 1.7698888778686523
[I 240428 07:32:51 trainer:32] loss: 1.6620776653289795
[I 240428 07:33:29 trainer:32] loss: 1.7788461446762085
[I 240428 07:34:06 trainer:32] loss: 1.8821247816085815
[I 240428 07:34:35 trainer:35] 
    Accuracy: 0.6619740777666999
[I 240428 07:35:11 trainer:32] loss: 1.0074942111968994
[I 240428 07:35:48 trainer:32] loss: 1.053176760673523
[I 240428 07:36:25 trainer:32] loss: 1.3339890241622925
[I 240428 07:37:01 trainer:32] loss: 1.1003096103668213
[I 240428 07:37:38 trainer:32] loss: 1.3112752437591553
[I 240428 07:38:14 trainer:32] loss: 1.350164532661438
[I 240428 07:38:51 trainer:32] loss: 1.0527299642562866
[I 240428 07:39:28 trainer:32] loss: 1.2383685111999512
[I 240428 07:40:05 trainer:32] loss: 1.4757473468780518
[I 240428 07:40:42 trainer:32] loss: 1.1018956899642944
[I 240428 07:41:19 trainer:32] loss: 1.3224034309387207
[I 240428 07:41:56 trainer:32] loss: 1.4249680042266846
[I 240428 07:42:33 trainer:32] loss: 1.2931337356567383
[I 240428 07:43:10 trainer:32] loss: 1.1711095571517944
[I 240428 07:43:47 trainer:32] loss: 1.534242033958435
[I 240428 07:44:23 trainer:32] loss: 1.3515156507492065
[I 240428 07:45:01 trainer:32] loss: 1.0072096586227417
[I 240428 07:45:38 trainer:32] loss: 1.2226271629333496
[I 240428 07:46:14 trainer:32] loss: 0.7963533401489258
[I 240428 07:46:51 trainer:32] loss: 0.8088428378105164
[I 240428 07:47:20 trainer:35] 
    Accuracy: 0.6570089730807577
[I 240428 07:47:57 trainer:32] loss: 1.2236073017120361
[I 240428 07:48:34 trainer:32] loss: 1.6812185049057007
[I 240428 07:49:10 trainer:32] loss: 0.9746172428131104
[I 240428 07:49:46 trainer:32] loss: 1.4851971864700317
[I 240428 07:50:24 trainer:38] 
    VALID Accuracy after epoch 8: 0.6491924227318046
[I 240428 08:00:59 trainer:40] 
    TRAIN Accuracy after epoch 8: 0.6637625946913827
[I 240428 08:00:59 trainer:13] 
    ====== Epoch 9/12 Training ======
[I 240428 08:01:36 trainer:32] loss: 2.1398370265960693
[I 240428 08:02:13 trainer:32] loss: 2.1138453483581543
[I 240428 08:02:50 trainer:32] loss: 2.0335888862609863
[I 240428 08:03:27 trainer:32] loss: 2.3547818660736084
[I 240428 08:04:03 trainer:32] loss: 2.2809228897094727
[I 240428 08:04:40 trainer:32] loss: 3.048734426498413
[I 240428 08:05:17 trainer:32] loss: 2.5063283443450928
[I 240428 08:05:54 trainer:32] loss: 2.716705322265625
[I 240428 08:06:31 trainer:32] loss: 2.8319802284240723
[I 240428 08:07:08 trainer:32] loss: 2.5320377349853516
[I 240428 08:07:45 trainer:32] loss: 2.485943078994751
[I 240428 08:08:22 trainer:32] loss: 2.554589033126831
[I 240428 08:08:59 trainer:32] loss: 2.805185317993164
[I 240428 08:09:37 trainer:32] loss: 2.488913059234619
[I 240428 08:10:13 trainer:32] loss: 2.544625759124756
[I 240428 08:10:50 trainer:32] loss: 2.605386972427368
[I 240428 08:11:27 trainer:32] loss: 2.255225658416748
[I 240428 08:12:05 trainer:32] loss: 2.3764562606811523
[I 240428 08:12:43 trainer:32] loss: 2.6024973392486572
[I 240428 08:13:21 trainer:32] loss: 2.8598814010620117
[I 240428 08:13:49 trainer:35] 
    Accuracy: 0.5241276171485544
[I 240428 08:14:26 trainer:32] loss: 1.8886748552322388
[I 240428 08:15:03 trainer:32] loss: 1.9228609800338745
[I 240428 08:15:39 trainer:32] loss: 1.7951269149780273
[I 240428 08:16:16 trainer:32] loss: 1.6887458562850952
[I 240428 08:16:53 trainer:32] loss: 1.88706636428833
[I 240428 08:17:30 trainer:32] loss: 1.7063242197036743
[I 240428 08:18:07 trainer:32] loss: 2.038027763366699
[I 240428 08:18:44 trainer:32] loss: 1.835077166557312
[I 240428 08:19:21 trainer:32] loss: 1.545889973640442
[I 240428 08:19:58 trainer:32] loss: 1.9093958139419556
[I 240428 08:20:34 trainer:32] loss: 1.8721009492874146
[I 240428 08:21:11 trainer:32] loss: 2.2885313034057617
[I 240428 08:21:49 trainer:32] loss: 2.0602011680603027
[I 240428 08:22:26 trainer:32] loss: 1.5566537380218506
[I 240428 08:23:03 trainer:32] loss: 1.9810423851013184
[I 240428 08:23:40 trainer:32] loss: 1.8317162990570068
[I 240428 08:24:17 trainer:32] loss: 1.5770964622497559
[I 240428 08:24:54 trainer:32] loss: 1.852717638015747
[I 240428 08:25:30 trainer:32] loss: 1.943455457687378
[I 240428 08:26:07 trainer:32] loss: 1.7584389448165894
[I 240428 08:26:36 trainer:35] 
    Accuracy: 0.5481555333998006
[I 240428 08:27:12 trainer:32] loss: 2.346402406692505
[I 240428 08:27:48 trainer:32] loss: 1.5763218402862549
[I 240428 08:28:25 trainer:32] loss: 1.472502589225769
[I 240428 08:29:01 trainer:32] loss: 1.9575260877609253
[I 240428 08:29:39 trainer:38] 
    VALID Accuracy after epoch 9: 0.5378664007976072
[I 240428 08:40:26 trainer:40] 
    TRAIN Accuracy after epoch 9: 0.5474517494200752
[I 240428 08:40:26 trainer:13] 
    ====== Epoch 10/12 Training ======
[I 240428 08:41:04 trainer:32] loss: 3.07428240776062
[I 240428 08:41:40 trainer:32] loss: 3.073763132095337
[I 240428 08:42:17 trainer:32] loss: 2.7393112182617188
[I 240428 08:42:54 trainer:32] loss: 3.296027898788452
[I 240428 08:43:30 trainer:32] loss: 2.9264423847198486
[I 240428 08:44:07 trainer:32] loss: 3.2036309242248535
[I 240428 08:44:44 trainer:32] loss: 3.7293519973754883
[I 240428 08:45:21 trainer:32] loss: 4.008224964141846
[I 240428 08:45:58 trainer:32] loss: 3.5504841804504395
[I 240428 08:46:35 trainer:32] loss: 4.305084705352783
[I 240428 08:47:11 trainer:32] loss: 4.329577445983887
[I 240428 08:47:48 trainer:32] loss: 4.216420650482178
[I 240428 08:48:25 trainer:32] loss: 4.5024027824401855
[I 240428 08:49:02 trainer:32] loss: 4.3285746574401855
[I 240428 08:49:39 trainer:32] loss: 3.688275098800659
[I 240428 08:50:16 trainer:32] loss: 4.064988136291504
[I 240428 08:50:53 trainer:32] loss: 4.549279689788818
[I 240428 08:51:30 trainer:32] loss: 4.484343528747559
[I 240428 08:52:07 trainer:32] loss: 4.922108173370361
[I 240428 08:52:44 trainer:32] loss: 4.4742255210876465
[I 240428 08:53:13 trainer:35] 
    Accuracy: 0.3396610169491525
[I 240428 08:53:50 trainer:32] loss: 2.890220880508423
[I 240428 08:54:26 trainer:32] loss: 3.6212005615234375
[I 240428 08:55:03 trainer:32] loss: 3.21122407913208
[I 240428 08:55:40 trainer:32] loss: 3.4425275325775146
[I 240428 08:56:16 trainer:32] loss: 3.624040365219116
[I 240428 08:56:53 trainer:32] loss: 3.255122423171997
[I 240428 08:57:29 trainer:32] loss: 2.797957181930542
[I 240428 08:58:06 trainer:32] loss: 3.022047758102417
[I 240428 08:58:42 trainer:32] loss: 3.1638875007629395
[I 240428 08:59:19 trainer:32] loss: 2.9287195205688477
[I 240428 08:59:56 trainer:32] loss: 3.406069278717041
[I 240428 09:00:32 trainer:32] loss: 3.1760802268981934
[I 240428 09:01:08 trainer:32] loss: 3.325289726257324
[I 240428 09:01:45 trainer:32] loss: 3.2401530742645264
[I 240428 09:02:22 trainer:32] loss: 3.0175602436065674
[I 240428 09:02:58 trainer:32] loss: 2.9426395893096924
[I 240428 09:03:36 trainer:32] loss: 3.2061989307403564
[I 240428 09:04:12 trainer:32] loss: 3.2816598415374756
[I 240428 09:04:48 trainer:32] loss: 2.4717423915863037
[I 240428 09:05:25 trainer:32] loss: 3.3258113861083984
[I 240428 09:05:54 trainer:35] 
    Accuracy: 0.3574277168494516
[I 240428 09:06:31 trainer:32] loss: 3.3925251960754395
[I 240428 09:07:07 trainer:32] loss: 2.4907329082489014
[I 240428 09:07:42 trainer:32] loss: 3.0927722454071045
[I 240428 09:08:18 trainer:32] loss: 2.933852434158325
[I 240428 09:08:55 trainer:38] 
    VALID Accuracy after epoch 10: 0.35926221335992026
[I 240428 09:19:31 trainer:40] 
    TRAIN Accuracy after epoch 10: 0.36736089064450544
[I 240428 09:19:31 trainer:13] 
    ====== Epoch 11/12 Training ======
[I 240428 09:20:08 trainer:32] loss: 5.764282703399658
[I 240428 09:20:45 trainer:32] loss: 5.797120571136475
[I 240428 09:21:22 trainer:32] loss: 6.428689002990723
[I 240428 09:21:59 trainer:32] loss: 6.821760177612305
[I 240428 09:22:35 trainer:32] loss: 6.6428093910217285
[I 240428 09:23:12 trainer:32] loss: 7.0862531661987305
[I 240428 09:23:48 trainer:32] loss: 7.413791656494141
[I 240428 09:24:25 trainer:32] loss: 7.716791152954102
[I 240428 09:25:02 trainer:32] loss: 7.848635673522949
[I 240428 09:25:39 trainer:32] loss: 7.9967851638793945
[I 240428 09:26:16 trainer:32] loss: 6.886710166931152
[I 240428 09:26:52 trainer:32] loss: 7.363315582275391
[I 240428 09:27:29 trainer:32] loss: 7.555161952972412
[I 240428 09:28:06 trainer:32] loss: 6.577193260192871
[I 240428 09:28:43 trainer:32] loss: 7.04732608795166
[I 240428 09:29:20 trainer:32] loss: 7.314720153808594
[I 240428 09:29:57 trainer:32] loss: 6.769326686859131
[I 240428 09:30:34 trainer:32] loss: 6.759921550750732
[I 240428 09:31:11 trainer:32] loss: 7.230247497558594
[I 240428 09:31:47 trainer:32] loss: 7.490365505218506
[I 240428 09:32:16 trainer:35] 
    Accuracy: 0.16586241276171484
[I 240428 09:32:52 trainer:32] loss: 5.916652202606201
[I 240428 09:33:29 trainer:32] loss: 5.6054887771606445
[I 240428 09:34:05 trainer:32] loss: 5.612185001373291
[I 240428 09:34:41 trainer:32] loss: 5.688026428222656
[I 240428 09:35:17 trainer:32] loss: 6.173783779144287
[I 240428 09:35:53 trainer:32] loss: 5.775058746337891
[I 240428 09:36:28 trainer:32] loss: 5.803696632385254
[I 240428 09:37:04 trainer:32] loss: 5.857728481292725
[I 240428 09:37:40 trainer:32] loss: 5.823973178863525
[I 240428 09:38:15 trainer:32] loss: 6.23789644241333
[I 240428 09:38:51 trainer:32] loss: 6.098498344421387
[I 240428 09:39:26 trainer:32] loss: 5.67351770401001
[I 240428 09:40:01 trainer:32] loss: 5.573032379150391
[I 240428 09:40:37 trainer:32] loss: 5.7766594886779785
[I 240428 09:41:12 trainer:32] loss: 5.888904571533203
[I 240428 09:41:47 trainer:32] loss: 5.840170383453369
[I 240428 09:42:23 trainer:32] loss: 5.776182651519775
[I 240428 09:42:58 trainer:32] loss: 5.750958442687988
[I 240428 09:43:33 trainer:32] loss: 5.96429443359375
[I 240428 09:44:09 trainer:32] loss: 6.213611602783203
[I 240428 09:44:37 trainer:35] 
    Accuracy: 0.1218344965104686
[I 240428 09:45:14 trainer:32] loss: 5.852622032165527
[I 240428 09:45:49 trainer:32] loss: 5.61479377746582
[I 240428 09:46:25 trainer:32] loss: 5.431735992431641
[I 240428 09:47:01 trainer:32] loss: 5.83827018737793
[I 240428 09:47:39 trainer:38] 
    VALID Accuracy after epoch 11: 0.12675972083748754
[I 240428 09:58:30 trainer:40] 
    TRAIN Accuracy after epoch 11: 0.12629388534113248
[I 240428 09:58:30 trainer:13] 
    ====== Epoch 12/12 Training ======
[I 240428 09:59:08 trainer:32] loss: 7.875572204589844
[I 240428 09:59:45 trainer:32] loss: 7.382562637329102
[I 240428 10:00:21 trainer:32] loss: 7.583841323852539
[I 240428 10:00:58 trainer:32] loss: 8.037487030029297
[I 240428 10:01:35 trainer:32] loss: 7.668196678161621
[I 240428 10:02:12 trainer:32] loss: 7.799612998962402
[I 240428 10:02:48 trainer:32] loss: 8.001483917236328
[I 240428 10:03:25 trainer:32] loss: 7.445450305938721
[I 240428 10:04:02 trainer:32] loss: 7.961293697357178
[I 240428 10:04:39 trainer:32] loss: 7.7200927734375
[I 240428 10:05:15 trainer:32] loss: 7.7524943351745605
[I 240428 10:05:52 trainer:32] loss: 8.22974681854248
[I 240428 10:06:29 trainer:32] loss: 7.60727071762085
[I 240428 10:07:06 trainer:32] loss: 7.99076509475708
[I 240428 10:07:43 trainer:32] loss: 7.529107570648193
[I 240428 10:08:20 trainer:32] loss: 7.676897048950195
[I 240428 10:08:57 trainer:32] loss: 7.532130241394043
[I 240428 10:09:34 trainer:32] loss: 7.479040622711182
[I 240428 10:10:11 trainer:32] loss: 7.8941497802734375
[I 240428 10:10:48 trainer:32] loss: 7.688075065612793
[I 240428 10:11:17 trainer:35] 
    Accuracy: 0.11330009970089731
[I 240428 10:11:54 trainer:32] loss: 6.119109630584717
[I 240428 10:12:30 trainer:32] loss: 6.272377967834473
[I 240428 10:13:06 trainer:32] loss: 6.3790388107299805
[I 240428 10:13:43 trainer:32] loss: 6.22946310043335
[I 240428 10:14:19 trainer:32] loss: 6.324373245239258
[I 240428 10:14:55 trainer:32] loss: 6.626523971557617
[I 240428 10:15:31 trainer:32] loss: 6.104435443878174
[I 240428 10:16:08 trainer:32] loss: 6.042294025421143
[I 240428 10:16:43 trainer:32] loss: 5.977713108062744
[I 240428 10:17:20 trainer:32] loss: 6.258580684661865
[I 240428 10:17:55 trainer:32] loss: 6.485157012939453
[I 240428 10:18:32 trainer:32] loss: 5.955052852630615
[I 240428 10:19:07 trainer:32] loss: 6.064207077026367
[I 240428 10:19:43 trainer:32] loss: 6.1677374839782715
[I 240428 10:20:18 trainer:32] loss: 6.032393932342529
[I 240428 10:20:54 trainer:32] loss: 6.469361305236816
[I 240428 10:21:29 trainer:32] loss: 6.320886611938477
[I 240428 10:22:04 trainer:32] loss: 6.442372798919678
[I 240428 10:22:39 trainer:32] loss: 6.327803611755371
[I 240428 10:23:14 trainer:32] loss: 6.144325256347656
[I 240428 10:23:40 trainer:35] 
    Accuracy: 0.10853439680957129
[I 240428 10:24:15 trainer:32] loss: 6.089895725250244
[I 240428 10:24:49 trainer:32] loss: 6.44827127456665
[I 240428 10:25:24 trainer:32] loss: 6.350973606109619
[I 240428 10:25:58 trainer:32] loss: 6.128432750701904
[I 240428 10:26:34 trainer:38] 
    VALID Accuracy after epoch 12: 0.11146560319042871
[I 240428 10:37:11 trainer:40] 
    TRAIN Accuracy after epoch 12: 0.11210317181598617
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1359: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cuda, whereas the model is on cpu. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cpu') before running `.generate()`.
  warnings.warn(
Traceback (most recent call last):
  File "/lnet/aic/personal/hryhoryd/thesis/script/gpt2_main.py", line 88, in <module>
    generated = generate_one(test_triple2, tokenizer, finetuned_model, device)
  File "/lnet/aic/personal/hryhoryd/thesis/script/trainer.py", line 91, in generate_one
    output = model.generate(input_ids, max_length=200)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 1391, in generate
    return self.greedy_search(
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 2179, in greedy_search
    outputs = self(
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1043, in forward
    transformer_outputs = self.transformer(
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 830, in forward
    inputs_embeds = self.wte(input_ids)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/home/hryhoryd/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2233, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
slurmstepd: error: common_file_write_uint32s: write pid 7108 to /sys/fs/cgroup/cgroup.procs failed: Device or resource busy
slurmstepd: error: Unable to move pid 7108 to init root cgroup /sys/fs/cgroup
slurmstepd: error: error unlocking cgroup '/sys/fs/cgroup/system.slice/slurmstepd.scope' : Bad file descriptor
